{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Convolutional Network (FCN) Training-Test (Tensorflow 2.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook it is demonstrated how to train a deep learning (DL) model built using an fully convolutional network(FCN) architecture to predict the column heights (CHs) in gold Nanoparticles (NPs) represented in Hight-Resolution Transmission Electron Microscopy (HRTEM) images using Tensorflow 2.2.0.\n",
    "\n",
    "Given the complexity of the problem, we realized that parallel compution is mandatory, since the learning process to accurately predict the CHs for each element requires a substantial amount of epochs. There two ways to implement a parallel DL calculation: **data parallelization** and **model parallelization**. Data parallelization is implemented using the **Mirrored Strategy** method from Tensorflow. A detailed explaination of data parallelization using Mirrored Strategy is provided here:\n",
    "\n",
    "**Mirrored Stategy (Data Parallelization)**:  https://www.tensorflow.org/tutorials/distribute/custom_training\n",
    "\n",
    "How does it work?:\n",
    "- All the variables and the model graph is replicated on the replicas.\n",
    "- Input is evenly distributed across the replicas.\n",
    "- Each replica calculates the loss and gradients for the input it received.\n",
    "- The gradients are synced across all the replicas by summing them.\n",
    "- After the sync, the same update is made to the copies of the variables on each replica.\n",
    "\n",
    "\n",
    "Model parallelization is implemented using the **Horovod** library. A detailed explaination of how to use **Horovod** for model parallelization is provided here:\n",
    "\n",
    "**Horovod (Model Parallelization)**: https://github.com/horovod/horovod.\n",
    "\n",
    "Also, we have impelemented a technique called Mixed Precision which accelerates tensors operation on GPUs with computing capability at least 7.0 and a technique called Accelerated Linear Algebra (XLA) from Tensorflow, in order to accelerate as much as possible the computation. More info can be found in the related webpages:\n",
    "\n",
    "**Mixed Precision**: https://www.tensorflow.org/guide/mixed_precision.\n",
    "\n",
    "\"Mixed precision is the combined use of different numerical precisions in a computational method. There are numerous benefits to using numerical formats with lower precision than 32-bit floating point. First, they require less memory, enabling the training and deployment of larger neural networks. Second, they require less memory bandwidth, thereby speeding up data transfer operations. Third, math operations run much faster in reduced precision, especially on GPUs with Tensor Core support for that precision. Mixed precision training achieves all these benefits while ensuring that no task-specific accuracy is lost compared to full precision training. It does so by identifying the steps that require full precision and using 32-bit floating point for only those steps while using 16-bit floating point everywhere else. Significant training speedups are experienced by switching to mixed precision -- up to 3x overall speedup on the most arithmetically intense model architectures. Half-precision floating point format (FP16) uses 16 bits, compared to 32 bits for single precision (FP32). Lowering the required memory enables training of larger models or training with larger mini-batches.\" (https://docs.nvidia.com/deeplearning/performance/mixed-precision-training/index.html)}.\n",
    "\n",
    "\n",
    "**XLA**: https://www.tensorflow.org/xla.\n",
    "\n",
    "\n",
    "Luckily, we benefit of a cluster of **4 NVIDIA V100 GPUs** with **computing capability of 7.0**. Even in this case, sufficiently accurately results have been achieved in at least 5 months ( approximately 600 epochs required) using model parallelization and at least 3 months (approximately 400 epochs required) using model parallelization. We have realized that model parallelization is a little bit faster in both the computation and in achieving a sufficiently high performance (less epochs required).\n",
    "\n",
    "In this notebook we illustrate both the implementations.\n",
    "\n",
    "\n",
    "The main files are *training_data-parallelization.py* and *training_model-parallelization.py*.In addition, the file *fcn.py* contains the implementation of the FCN, while *training_utils.py* contains the modules to perform random imaging transormations of the input images and to calculate the R^2 between the predicted and true CHs, as well as to plot the input data in a debug folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Parallelization Implementation\n",
    "\n",
    "Here we provide the code to implement the training of the FCN using data parallelization in Tensorflow 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -Step 1: importing the libraries:\n",
    "\n",
    "- **Numpy**.\n",
    "\n",
    "- **Tensorflow**. In particular, we import the module mixed_precision to implement the mixed precision technique.\n",
    "\n",
    "- **fcn**: file containing the architecture of the FCN.\n",
    "\n",
    "- **training_utils**: file containing the modules for the calculation of the R^2 (R2_CHs), the implementation of the random transformations on the input images (Random_Imaging) and plotting in debug folder (plot_debug).\n",
    "\n",
    "- **time, datetime**: libraries to manage timing, used to calculated to processing time of the learning process in terms of images/second.\n",
    "\n",
    "- **loggin,platform**: print on which host the code is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "from fcn import FCN\n",
    "from training_utils import R2_CHs,Random_Imaging,plot_debug\n",
    "\n",
    "import os\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import logging\n",
    "import platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Step 2: defining the directories path to load data and save results:\n",
    "\n",
    "- **training_folder_path, test_folder_path**: paths to training and test data. The data are saved in numpy arrays data_1.npy, data_2.npy, etc. as tensors which contain both the images and the labels maps.\n",
    "\n",
    "\n",
    "- **training_results_folder_path, test_results_folder_path**: paths to the parent directories containing the saved training and test results.\n",
    "\n",
    "\n",
    "- **debug_folder_path**: path to debug directory to save the plots of the input images and labels just to check what it is going through the network.\n",
    "\n",
    "\n",
    "- **weights_folder_path**: path to the directory to save the weights of the FCN at each epoch.\n",
    "\n",
    "\n",
    "- **training_learning_curve_folder_path,test_learning_curve_folder_path**: paths to the directories containing the training and test learning curves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_folder_path = '../training_data/data/'\n",
    "test_folder_path = '../test_data/data/'\n",
    "\n",
    "training_results_folder_path = 'results_data-parallelization/training_results/'\n",
    "debug_folder_path = training_results_folder_path + 'debug/'\n",
    "weights_folder_path = training_results_folder_path + 'weights/'\n",
    "training_learning_curve_folder_path = training_results_folder_path + 'train_learning_curve/'\n",
    "\n",
    "test_results_folder_path = 'results_data-parallelization/test_results/'\n",
    "test_learning_curve_folder_path = test_results_folder_path + 'test_learning_curve/'\n",
    "\n",
    "\n",
    "if training_results_folder_path and not os.path.exists(training_results_folder_path):\n",
    "    os.makedirs(training_results_folder_path)\n",
    "\n",
    "if debug_folder_path and not os.path.exists(debug_folder_path):\n",
    "    os.makedirs(debug_folder_path)\n",
    "\n",
    "if weights_folder_path and not os.path.exists(weights_folder_path):\n",
    "    os.makedirs(weights_folder_path)\n",
    "\n",
    "if training_learning_curve_folder_path and not os.path.exists(training_learning_curve_folder_path):\n",
    "    os.makedirs(training_learning_curve_folder_path)\n",
    "\n",
    "if test_results_folder_path and not os.path.exists(test_results_folder_path):\n",
    "    os.makedirs(test_results_folder_path)\n",
    "\n",
    "if test_learning_curve_folder_path and not os.path.exists(test_learning_curve_folder_path):\n",
    "    os.makedirs(test_learning_curve_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Step 3: defining the computing techniques: Mirrored Strategy, Mixed Precision, Config Proto and XLA\n",
    "\n",
    " - **Mirrored Strategy**: implementation of data parallelization. **For the sake of the visualization of the distributed training implementation**, the code is run on my personal laptop on **2 CPUs cores**. The results provided in the paper are obtained running the model on a cluster of **4 V-100 GPUs**.\n",
    " \n",
    " - **Mixed Precision**: mixed precision should be activated (mp = True) only if the cod is run on an NVIDIS GPU with a computing capability at least of 7.0. In other case, mixed precison actually slows down the calculation. \n",
    " \n",
    " - **Config Proto**: method to define server parameters for training. In particular:\n",
    " \n",
    " \n",
    "   - **allow_soft_placement**: dynamic allocation of GPU memory.\n",
    "   \n",
    "   - **log_device_placement**: printing of device information.\n",
    "   \n",
    "   - **gpu_options.allow_growth**: allowing to allocate only the memory required by the process, instead of allocating the full memory of the device where the process runs.\n",
    "   \n",
    "   - **gpu_options.force_gpu_compatible**: force all tensors to be gpu_compatible. All CPU tensors will be allocated with Cuda pinned memory.\n",
    "   \n",
    "   - **graph_options.optimizer_options.global_jit_level**: XLA activation.\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Some requested devices in `tf.distribute.Strategy` are not visible to TensorFlow: /job:localhost/replica:0/task:0/device:CPU:2,/job:localhost/replica:0/task:0/device:CPU:1\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:1', '/job:localhost/replica:0/task:0/device:CPU:2')\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mirrored Strategy (1)\n",
    "#strategy = tf.distribute.MirroredStrategy()\n",
    "strategy = tf.distribute.MirroredStrategy(['/cpu:1','/cpu:2'])\n",
    "\n",
    "num_devices = strategy.num_replicas_in_sync\n",
    "\n",
    "# Mixed Precision (2) \n",
    "# set to True only if running on a device with computing capability at least 7.0 (ex. V-100 GPU)\n",
    "mp = False\n",
    "\n",
    "if mp:\n",
    "\n",
    "    policy = mixed_precision.Policy('mixed_float16')\n",
    "\n",
    "    mixed_precision.set_policy(policy)\n",
    "\n",
    "# set gpus options\n",
    "config_proto = tf.compat.v1.ConfigProto()\n",
    "\n",
    "config_proto.allow_soft_placement = True\n",
    "\n",
    "config_proto.log_device_placement = True\n",
    "\n",
    "config_proto.gpu_options.allow_growth = True\n",
    "\n",
    "config_proto.gpu_options.force_gpu_compatible = True\n",
    "\n",
    "# XLA (3)\n",
    "config_proto.graph_options.optimizer_options.global_jit_level = tf.compat.v1.OptimizerOptions.ON_1\n",
    "\n",
    "# session definition\n",
    "sess = tf.compat.v1.InteractiveSession(config = config_proto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -Step 4: Training-Test datasets definition\n",
    "\n",
    "   - **training_data_path**: path to training data files in '.npy' format.\n",
    "   \n",
    "   \n",
    "   - **train_dataset**: definition of the trainig dataset object using the Tensorflow function **data.Dataset.list_files**. Shuffling of the data which is required in the training process is implemented using the **.shuffle** method,setting the **buffer_size** as the total number of training data and **batch_size** as the global batch size.\n",
    "   \n",
    "   \n",
    "   - **batch_size_per_replica**: batch of data allocated to a single device. In the example of this notebook, the batch_size_per_replica is set to 4.\n",
    "   \n",
    "   \n",
    "   - **global_batch_size**: batch of data allocated among all the used devices. In the example of this notebook, we use 2 CPU devices, and since batch_size_per_replica is 4, the global_batch_size is 8. Since there are 80 training data, we have 10 global batches in total.\n",
    "   \n",
    "   \n",
    "   - **distributed_train_dataset**: the training dataset object implemented for parallel distribution using the Mirrored Strategy technique.\n",
    "   \n",
    "   \n",
    "All the operations described above are used for the test dataset as well.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_path = training_folder_path + str('*.npy')\n",
    "test_data_path = test_folder_path + str('*.npy')\n",
    "\n",
    "train_dataset = tf.data.Dataset.list_files(training_data_path)\n",
    "test_dataset = tf.data.Dataset.list_files(test_data_path)\n",
    "\n",
    "num_training_data = len(os.listdir(training_folder_path))\n",
    "num_test_data = len(os.listdir(test_folder_path))\n",
    "\n",
    "batch_size_per_replica = 4\n",
    "\n",
    "global_batch_size = batch_size_per_replica * num_devices\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size = num_training_data).batch(batch_size = global_batch_size)\n",
    "test_dataset = test_dataset.batch(batch_size = global_batch_size)\n",
    "\n",
    "num_global_batches_train = num_training_data // global_batch_size\n",
    "\n",
    "distributed_train_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
    "distributed_test_dataset = strategy.experimental_distribute_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -Step 5: Model definition\n",
    "\n",
    "- **get_model**: function to define the model on the basis of the implemented FCN network architecture.\n",
    "\n",
    "\n",
    "- **with strategy.scope()**: model definition under the data distribution strategy.\n",
    "\n",
    "\n",
    "- **optimizer**: Adam optimizer is used to compile the model. If mixed precision is enabled, the optimizer must be scaled, since the mixed precision operation involves the calculation of a scaled loss. Loss scaling is used to preserve small gradient values.\n",
    "\n",
    "\n",
    "- **loss_object**: the mean squared error (MSE) is adopted as loss function. With Mirrored Strategy, the model on each replica does a forward pass with its respective input and calculates the loss. Now, instead of dividing the loss by the number of examples in its respective input (BATCH_SIZE_PER_REPLICA), **the loss should be divided by the GLOBAL_BATCH_SIZE**. This needs to be done because after the gradients are calculated on each replica, they are **synced across the replicas by summing them (reduction)**. If using **tf.keras.losses classes** (as in the example below), **the loss reduction needs to be explicitly specified to be NONE**, so we can disable automatic reduction and explicitly define it using other functions which are **appropriate for distributed training**. \n",
    "\n",
    "  In particular, we use **tf.nn.compute_average_loss(per_example_loss,global_batch_size = GLOBAL_BATCH_SIZE)** to perform the loss reduction. \n",
    "  \n",
    "\n",
    "  It should be noted that even if the data are distributed across different devices (CPUs like in this example or GPUs), the reducction takes place always on the head CPU, labeled as CPU:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "def get_model(FCN,input_shape, output_channels):\n",
    "\n",
    "    input_channel = 1\n",
    "\n",
    "    input_tensor = tf.keras.Input(shape = input_shape+(input_channel,))\n",
    "\n",
    "    model = FCN(input_tensor, output_channels)\n",
    "\n",
    "    return model\n",
    "\n",
    "input_shape = (256,256)\n",
    "    \n",
    "output_channels = 1\n",
    "    \n",
    "with strategy.scope():\n",
    "\n",
    "    model = get_model(FCN, input_shape, output_channels)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "    if mp:\n",
    "        \n",
    "        optimizer = mixed_precision.LossScaleOptimizer(optimizer, loss_scale='dynamic')\n",
    "\n",
    "    loss_object = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "\n",
    "    def compute_loss(labels,predictions):\n",
    "\n",
    "        per_example_loss = loss_object(labels, predictions)\n",
    "\n",
    "        per_example_loss /= tf.cast(tf.reduce_prod(tf.shape(labels)[1:]), tf.float32)\n",
    "\n",
    "        return tf.nn.compute_average_loss(per_example_loss, global_batch_size = labels.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -Step 6: Extract a global batch\n",
    "\n",
    " - **get_global_batch**: function to extract a global batch of images and labels. The input is 'global_batch' which is a list containing a batch of paths data in '.npy' format. Each data is loaded in a for loop and the batch of images and labels are populated. The images and labels are 4D tensors, which is the appropriate format for deep learning computation.\n",
    " \n",
    "  Random transformations (lighting, blurring, increasing/decreasing contrast and rotations are applied to the images with the class **Random_Imaging**. \n",
    "  The function **plot_debug** is used to save a plot of the images and the label maps for each element in debug folder, in order to visualize the input going through the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_global_batch(global_batch):\n",
    "\n",
    "    global_batch = np.array(global_batch)\n",
    "\n",
    "    global_batch_images = []\n",
    "\n",
    "    global_batch_labels = []\n",
    "\n",
    "    for i in range(len(global_batch)):\n",
    "        \n",
    "        \n",
    "        # load numpy file\n",
    "        data = np.load(global_batch[i])\n",
    "        \n",
    "        # extract the image\n",
    "        img = data[:,:,:,0]\n",
    "        img = img.reshape(img.shape+(1,)).astype(np.float32)\n",
    "\n",
    "        # extract the label segmentation map\n",
    "        lbl = data[:,:,:,1:]\n",
    "        \n",
    "        # apply random transformations\n",
    "        rnd_imgng = Random_Imaging(image=img,labels=lbl)\n",
    "        img,lbl = rnd_imgng.get_trasform()\n",
    "\n",
    "        global_batch_images.append(img)\n",
    "\n",
    "        global_batch_labels.append(lbl)\n",
    "        \n",
    "        # plot the batch of images and labels in debug folder to visualize it\n",
    "        plot_debug(img, lbl, i, debug_folder_path)\n",
    "\n",
    "    global_batch_images = np.concatenate(global_batch_images)\n",
    "\n",
    "    global_batch_labels = np.concatenate(global_batch_labels)\n",
    "\n",
    "    return  [global_batch_images, global_batch_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -Step 6: Training and Test functions definition\n",
    "\n",
    "  - **train_step**: functions wich define the training process (forward pass + loss calculation + backpropagation + update of the model's parameters). The input is a local batch of data (batch of data for a single device).\n",
    "  \n",
    "  \n",
    "  - **test_step**: functions wich define the test process (forward pass + loss calculation). The input is a local batch of data (batch of data for a single device).\n",
    "  \n",
    "  \n",
    "  - **@tf.function**: compilation of a function into a callable TensorFlow graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(local_batch):\n",
    "    \n",
    "    local_batch_images, local_batch_labels = local_batch\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        local_batch_predictions = model(local_batch_images, training=True)\n",
    "\n",
    "        train_loss = compute_loss(local_batch_labels, local_batch_predictions)\n",
    "\n",
    "\n",
    "        if mp:\n",
    "\n",
    "            scaled_train_loss = optimizer.get_scaled_loss(train_loss)\n",
    "\n",
    "\n",
    "    if mp:\n",
    "\n",
    "        scaled_gradients = tape.gradient(scaled_train_loss, model.trainable_variables)\n",
    "\n",
    "        gradients = optimizer.get_unscaled_gradients(scaled_gradients)\n",
    "\n",
    "    else:\n",
    "\n",
    "        gradients = tape.gradient(train_loss, model.trainable_variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return train_loss, local_batch_predictions\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def test_step(local_batch):\n",
    "\n",
    "    local_batch_images, local_batch_labels = local_batch\n",
    "\n",
    "    local_batch_predictions = model(local_batch_images, training = False)\n",
    "\n",
    "    test_loss = compute_loss(local_batch_labels, local_batch_predictions)\n",
    "\n",
    "    return test_loss,local_batch_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -Step 7: Parallel Training and Test definition\n",
    "\n",
    "\n",
    "  - **distributed_train_step**: implementation of the training step in the parallel distribution. The loss and predictions are calculated on each device using **strategy.run** applied to the **train_step** function and the **gloabal_batch**. The **loss reduction** is implemented using the **.reduce** method of the strategy.\n",
    "  \n",
    "  \n",
    "   - **distributed_test_step**: implementation of the test step in the parallel distribution. The loss and predictions are calculated on each device using **strategy.run** applied to the **test_step** function and the **gloabal_batch**. The **loss reduction** is implemented using the **.reduce** method of the strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def distributed_train_step(global_batch):\n",
    "\n",
    "    per_replica_losses, per_replica_predictions = strategy.run(train_step, args=(global_batch,))\n",
    "\n",
    "    loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,axis=None)\n",
    "    predictions = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_predictions,axis=None)\n",
    "\n",
    "    return loss,predictions\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def distributed_test_step(global_batch):\n",
    "\n",
    "    per_replica_losses, per_replica_predictions = strategy.run(test_step, args=(global_batch,))\n",
    "\n",
    "    loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
    "    predictions = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_predictions, axis=None)\n",
    "\n",
    "    return loss, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -Step 8: Training and Test loop definition\n",
    "\n",
    "  - **train_test_loop**: function wich implements the training and test loop. Inputs:\n",
    "  \n",
    "  \n",
    "   - **first_epoch**: epoch at which the run should start. If the training is run from scratch, of course first_epoch has to be set to 0. If for any reason the training is interrupted (out of memory problems, server shutdown etc.) setting first_epoch allows to re-load the saved results up to the epoch when training was interrupted and re-start training from there.\n",
    "   \n",
    "   \n",
    "   - **num_epochs**: number of epochs for training the model.\n",
    "   \n",
    "   - **save_every**: to save space, we save the weights with a certain epochs step. In this example we save the wieghts every 5 epochs.\n",
    "   \n",
    "   \n",
    "At the beginning of the run, the code prints out the host where it is running as well as the number of GPUs used in the computation.\n",
    "   \n",
    "After each batch has been processed, the code prints the running loss and average R2, as well as the processing frequency (PF), calculated as the number of images per second processed by the model. In my personal laptop the processing frequency is very low (0.2 imgs/s), with P-100 GPU it's 20 imgs/s and with V-100 GPU it's 40 imgs/s.\n",
    "\n",
    "\n",
    "The **R2_CHs** is used to calculate the R2 between the predicted and the true CHs. It should be noted that the R2 requires a substantial amount of epochs to grow from its initial value of 0.\n",
    "\n",
    "\n",
    "The **loss and R2 results**, as well as the **model's parameter**s are saved in the appropriate folders defined in **Step 2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_test_loop(first_epoch,num_epochs, save_every):\n",
    "    \n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "    logging.getLogger('tensorflow').setLevel(logging.FATAL)\n",
    "\n",
    "    print(\"Running on host '{}'\".format(platform.node()))\n",
    "    print('Running on {} devices'.format(num_devices))\n",
    "\n",
    "\n",
    "    train_loss_learning_curve = []\n",
    "    train_r2_learning_curve = []\n",
    "\n",
    "    test_loss_learning_curve = []\n",
    "    test_r2_learning_curve = []\n",
    "\n",
    "    if first_epoch > 0:\n",
    "        model.load_weights(weights_folder_path+'epoch-{}.h5'.format(first_epoch))\n",
    "\n",
    "        train_loss_learning_curve = list(np.load(training_learning_curve_folder_path+'train_loss_learning_curve.npy'))\n",
    "        train_r2_learning_curve = list(np.load(training_learning_curve_folder_path+'train_r2_learning_curve.npy'))\n",
    "        test_loss_learning_curve = list(np.load(test_learning_curve_folder_path+'test_loss_learning_curve.npy'))\n",
    "        test_r2_learning_curve = list(np.load(test_learning_curve_folder_path+'test_r2_learning_curve.npy'))\n",
    "\n",
    "\n",
    "    for epoch in range(first_epoch, first_epoch + num_epochs):\n",
    "\n",
    "        total_train_loss = 0.0\n",
    "\n",
    "        total_average_r2_train = 0.0\n",
    "\n",
    "        processed_batches_train = 0\n",
    "\n",
    "        for train_batch_index,train_batch in enumerate(train_dataset):\n",
    "\n",
    "            train_images,train_labels = get_global_batch(train_batch)\n",
    "\n",
    "            num_images = train_images.shape[0]\n",
    "\n",
    "            before = time.time()\n",
    "\n",
    "            train_loss,train_predictions = distributed_train_step([train_images,train_labels])\n",
    "\n",
    "            total_train_loss = total_train_loss + train_loss\n",
    "\n",
    "            processed_batches_train += 1\n",
    "\n",
    "            train_loss = total_train_loss / processed_batches_train\n",
    "\n",
    "            r2_CHs = R2_CHs(train_predictions, train_labels)\n",
    "            r2_train = r2_CHs.get_r2_batch()\n",
    "\n",
    "            total_average_r2_train += r2_train\n",
    "            r2_average_train = total_average_r2_train/processed_batches_train\n",
    "\n",
    "            totaltime = time.time() - before\n",
    "            \n",
    "            if (train_batch_index +1) % 1 == 0:\n",
    "                \n",
    "                \n",
    "               # print('Epoch [{}/{}] : Batch [{}/{}] : Train Loss = {:.4f}, Train R2 = {:.4f}, Processing Frequency = {:.1f} imgs/s'.format(epoch+1,\n",
    "                print('Epoch [{}/{}] : Batch [{}/{}] : Train Loss = {:.4f}, Train R2 = {:.4f}'.format(epoch+1,                                                                                                                        \n",
    "                                                                                first_epoch + num_epochs,\n",
    "                                                                                train_batch_index +1,\n",
    "                                                                                num_global_batches_train,\n",
    "                                                                                train_loss,\n",
    "                                                                                r2_average_train))\n",
    "                                                                          #      num_images/totaltime))\n",
    "\n",
    "            \n",
    "        total_test_loss = 0\n",
    "\n",
    "        total_average_r2_test = 0.0\n",
    "\n",
    "        processed_batches_test = 0\n",
    "\n",
    "        for test_batch_index,test_batch in enumerate(test_dataset):\n",
    "\n",
    "            test_images, test_labels = get_global_batch(test_batch)\n",
    "\n",
    "            test_loss, test_predictions = distributed_test_step([test_images, test_labels])\n",
    "\n",
    "            total_test_loss += test_loss\n",
    "\n",
    "            processed_batches_test += 1\n",
    "\n",
    "            test_loss = total_test_loss/processed_batches_test\n",
    "\n",
    "            r2_CHs = R2_CHs(test_predictions, test_labels)\n",
    "            r2_test = r2_CHs.get_r2_batch()\n",
    "\n",
    "            total_average_r2_test += r2_test\n",
    "            r2_average_test = total_average_r2_test / processed_batches_test\n",
    "\n",
    "        print('Epoch [{}/{}]: Test Loss = {:.4f}, Test R2 = {:.4f}'.format(epoch + 1,\n",
    "                                                                           first_epoch + num_epochs,\n",
    "                                                                           test_loss,\n",
    "                                                                           r2_average_test))\n",
    "\n",
    "\n",
    "        train_loss_learning_curve.append(train_loss)\n",
    "        train_loss_learning_curve_array = np.array(train_loss_learning_curve)\n",
    "\n",
    "        train_r2_learning_curve.append(r2_train)\n",
    "        train_r2_learning_curve_array = np.array(train_r2_learning_curve)\n",
    "\n",
    "        np.save(training_learning_curve_folder_path+'train_loss_learning_curve',train_loss_learning_curve_array)\n",
    "        np.save(training_learning_curve_folder_path+'train_r2_learning_curve',train_r2_learning_curve_array)\n",
    "\n",
    "\n",
    "        test_loss_learning_curve.append(test_loss)\n",
    "        test_loss_learning_curve_array = np.array(test_loss_learning_curve)\n",
    "\n",
    "        test_r2_learning_curve.append(r2_test)\n",
    "        test_r2_learning_curve_array = np.array(test_r2_learning_curve)\n",
    "\n",
    "        np.save(test_learning_curve_folder_path+'test_loss_learning_curve',test_loss_learning_curve_array)\n",
    "        np.save(test_learning_curve_folder_path+'test_r2_learning_curve',test_r2_learning_curve_array)\n",
    "\n",
    "        if epoch % save_every == 0:\n",
    "            model.save_weights(weights_folder_path+'epoch-{}.h5'.format(epoch+1))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and test loop can be run by simply defining **first_epoch** and **num_epochs** and calling the function **train_test_loop**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on host 'Marcos-MBP.attlocal.net'\n",
      "Running on 2 devices\n",
      "Epoch [1/500] : Batch [1/10] : Train Loss = 0.6586, Train R2 = 0.0000\n",
      "Epoch [1/500] : Batch [2/10] : Train Loss = 0.5955, Train R2 = 0.0000\n",
      "Epoch [1/500] : Batch [3/10] : Train Loss = 0.5512, Train R2 = 0.0097\n",
      "Epoch [1/500] : Batch [4/10] : Train Loss = 0.4608, Train R2 = 0.0672\n",
      "Epoch [1/500] : Batch [5/10] : Train Loss = 0.4282, Train R2 = 0.0782\n",
      "Epoch [1/500] : Batch [6/10] : Train Loss = 0.4013, Train R2 = 0.1105\n",
      "Epoch [1/500] : Batch [7/10] : Train Loss = 0.4071, Train R2 = 0.1142\n",
      "Epoch [1/500] : Batch [8/10] : Train Loss = 0.3781, Train R2 = 0.1288\n",
      "Epoch [1/500] : Batch [9/10] : Train Loss = 0.3536, Train R2 = 0.1528\n",
      "Epoch [1/500] : Batch [10/10] : Train Loss = 0.3552, Train R2 = 0.1708\n",
      "Epoch [1/500]: Test Loss = 76.5387, Test R2 = 0.0000\n",
      "Epoch [2/500] : Batch [1/10] : Train Loss = 0.4712, Train R2 = 0.4067\n",
      "Epoch [2/500] : Batch [2/10] : Train Loss = 0.3433, Train R2 = 0.3603\n",
      "Epoch [2/500] : Batch [3/10] : Train Loss = 0.2785, Train R2 = 0.3480\n",
      "Epoch [2/500] : Batch [4/10] : Train Loss = 0.2394, Train R2 = 0.3403\n",
      "Epoch [2/500] : Batch [5/10] : Train Loss = 0.2223, Train R2 = 0.3522\n",
      "Epoch [2/500] : Batch [6/10] : Train Loss = 0.2041, Train R2 = 0.3666\n",
      "Epoch [2/500] : Batch [7/10] : Train Loss = 0.1936, Train R2 = 0.3619\n",
      "Epoch [2/500] : Batch [8/10] : Train Loss = 0.1838, Train R2 = 0.3734\n",
      "Epoch [2/500] : Batch [9/10] : Train Loss = 0.1787, Train R2 = 0.3670\n",
      "Epoch [2/500] : Batch [10/10] : Train Loss = 0.1774, Train R2 = 0.3642\n",
      "Epoch [2/500]: Test Loss = 561.2484, Test R2 = 0.0000\n",
      "Epoch [3/500] : Batch [1/10] : Train Loss = 0.1967, Train R2 = 0.2566\n",
      "Epoch [3/500] : Batch [2/10] : Train Loss = 0.3974, Train R2 = 0.2872\n",
      "Epoch [3/500] : Batch [3/10] : Train Loss = 0.3231, Train R2 = 0.3205\n",
      "Epoch [3/500] : Batch [4/10] : Train Loss = 0.2654, Train R2 = 0.3304\n",
      "Epoch [3/500] : Batch [5/10] : Train Loss = 0.2293, Train R2 = 0.3290\n",
      "Epoch [3/500] : Batch [6/10] : Train Loss = 0.2094, Train R2 = 0.3223\n",
      "Epoch [3/500] : Batch [7/10] : Train Loss = 0.1958, Train R2 = 0.3463\n",
      "Epoch [3/500] : Batch [8/10] : Train Loss = 0.1817, Train R2 = 0.3769\n",
      "Epoch [3/500] : Batch [9/10] : Train Loss = 0.1696, Train R2 = 0.3839\n",
      "Epoch [3/500] : Batch [10/10] : Train Loss = 0.1569, Train R2 = 0.3821\n",
      "Epoch [3/500]: Test Loss = 461.5288, Test R2 = 0.0000\n",
      "Epoch [4/500] : Batch [1/10] : Train Loss = 0.0649, Train R2 = 0.3574\n",
      "Epoch [4/500] : Batch [2/10] : Train Loss = 0.3425, Train R2 = 0.3581\n",
      "Epoch [4/500] : Batch [3/10] : Train Loss = 0.2586, Train R2 = 0.3537\n",
      "Epoch [4/500] : Batch [4/10] : Train Loss = 0.2211, Train R2 = 0.3837\n",
      "Epoch [4/500] : Batch [5/10] : Train Loss = 0.2051, Train R2 = 0.3968\n",
      "Epoch [4/500] : Batch [6/10] : Train Loss = 0.1880, Train R2 = 0.4019\n",
      "Epoch [4/500] : Batch [7/10] : Train Loss = 0.1785, Train R2 = 0.4216\n",
      "Epoch [4/500] : Batch [8/10] : Train Loss = 0.1695, Train R2 = 0.4170\n",
      "Epoch [4/500] : Batch [9/10] : Train Loss = 0.1625, Train R2 = 0.4073\n",
      "Epoch [4/500] : Batch [10/10] : Train Loss = 0.1553, Train R2 = 0.4014\n",
      "Epoch [4/500]: Test Loss = 65.5950, Test R2 = 0.0019\n",
      "Epoch [5/500] : Batch [1/10] : Train Loss = 0.0571, Train R2 = 0.3408\n",
      "Epoch [5/500] : Batch [2/10] : Train Loss = 0.0575, Train R2 = 0.3556\n",
      "Epoch [5/500] : Batch [3/10] : Train Loss = 0.0635, Train R2 = 0.3757\n",
      "Epoch [5/500] : Batch [4/10] : Train Loss = 0.1103, Train R2 = 0.4040\n",
      "Epoch [5/500] : Batch [5/10] : Train Loss = 0.1071, Train R2 = 0.3954\n",
      "Epoch [5/500] : Batch [6/10] : Train Loss = 0.1074, Train R2 = 0.3928\n",
      "Epoch [5/500] : Batch [7/10] : Train Loss = 0.1030, Train R2 = 0.4021\n",
      "Epoch [5/500] : Batch [8/10] : Train Loss = 0.1022, Train R2 = 0.3929\n",
      "Epoch [5/500] : Batch [9/10] : Train Loss = 0.1000, Train R2 = 0.3835\n",
      "Epoch [5/500] : Batch [10/10] : Train Loss = 0.0974, Train R2 = 0.3930\n",
      "Epoch [5/500]: Test Loss = 50.1385, Test R2 = 0.0114\n",
      "Epoch [6/500] : Batch [1/10] : Train Loss = 0.0807, Train R2 = 0.4215\n",
      "Epoch [6/500] : Batch [2/10] : Train Loss = 0.0686, Train R2 = 0.3878\n",
      "Epoch [6/500] : Batch [3/10] : Train Loss = 0.0711, Train R2 = 0.4505\n",
      "Epoch [6/500] : Batch [4/10] : Train Loss = 0.0626, Train R2 = 0.4219\n",
      "Epoch [6/500] : Batch [5/10] : Train Loss = 0.0644, Train R2 = 0.4277\n",
      "Epoch [6/500] : Batch [6/10] : Train Loss = 0.0627, Train R2 = 0.4217\n",
      "Epoch [6/500] : Batch [7/10] : Train Loss = 0.0617, Train R2 = 0.4168\n",
      "Epoch [6/500] : Batch [8/10] : Train Loss = 0.0616, Train R2 = 0.4125\n",
      "Epoch [6/500] : Batch [9/10] : Train Loss = 0.0819, Train R2 = 0.4369\n",
      "Epoch [6/500] : Batch [10/10] : Train Loss = 0.0779, Train R2 = 0.4342\n",
      "Epoch [6/500]: Test Loss = 7.4257, Test R2 = 0.0467\n",
      "Epoch [7/500] : Batch [1/10] : Train Loss = 0.0889, Train R2 = 0.6063\n",
      "Epoch [7/500] : Batch [2/10] : Train Loss = 0.0721, Train R2 = 0.4765\n",
      "Epoch [7/500] : Batch [3/10] : Train Loss = 0.0650, Train R2 = 0.4540\n",
      "Epoch [7/500] : Batch [4/10] : Train Loss = 0.0598, Train R2 = 0.4361\n",
      "Epoch [7/500] : Batch [5/10] : Train Loss = 0.0610, Train R2 = 0.4029\n",
      "Epoch [7/500] : Batch [6/10] : Train Loss = 0.0590, Train R2 = 0.3857\n",
      "Epoch [7/500] : Batch [7/10] : Train Loss = 0.0562, Train R2 = 0.3817\n",
      "Epoch [7/500] : Batch [8/10] : Train Loss = 0.0626, Train R2 = 0.3886\n",
      "Epoch [7/500] : Batch [9/10] : Train Loss = 0.0625, Train R2 = 0.3780\n",
      "Epoch [7/500] : Batch [10/10] : Train Loss = 0.0605, Train R2 = 0.3790\n",
      "Epoch [7/500]: Test Loss = 1.4811, Test R2 = 0.0416\n",
      "Epoch [8/500] : Batch [1/10] : Train Loss = 0.0508, Train R2 = 0.4828\n",
      "Epoch [8/500] : Batch [2/10] : Train Loss = 0.0467, Train R2 = 0.4342\n",
      "Epoch [8/500] : Batch [3/10] : Train Loss = 0.0471, Train R2 = 0.3940\n",
      "Epoch [8/500] : Batch [4/10] : Train Loss = 0.0471, Train R2 = 0.3714\n",
      "Epoch [8/500] : Batch [5/10] : Train Loss = 0.0471, Train R2 = 0.3564\n",
      "Epoch [8/500] : Batch [6/10] : Train Loss = 0.0491, Train R2 = 0.3695\n",
      "Epoch [8/500] : Batch [7/10] : Train Loss = 0.0687, Train R2 = 0.4179\n",
      "Epoch [8/500] : Batch [8/10] : Train Loss = 0.0645, Train R2 = 0.4082\n",
      "Epoch [8/500] : Batch [9/10] : Train Loss = 0.0619, Train R2 = 0.4178\n",
      "Epoch [8/500] : Batch [10/10] : Train Loss = 0.0646, Train R2 = 0.4387\n",
      "Epoch [8/500]: Test Loss = 0.5018, Test R2 = 0.0157\n",
      "Epoch [9/500] : Batch [1/10] : Train Loss = 0.0310, Train R2 = 0.3635\n",
      "Epoch [9/500] : Batch [2/10] : Train Loss = 0.0336, Train R2 = 0.3973\n",
      "Epoch [9/500] : Batch [3/10] : Train Loss = 0.0404, Train R2 = 0.3890\n",
      "Epoch [9/500] : Batch [4/10] : Train Loss = 0.0395, Train R2 = 0.3805\n",
      "Epoch [9/500] : Batch [5/10] : Train Loss = 0.0411, Train R2 = 0.4069\n",
      "Epoch [9/500] : Batch [6/10] : Train Loss = 0.0687, Train R2 = 0.4505\n",
      "Epoch [9/500] : Batch [7/10] : Train Loss = 0.0663, Train R2 = 0.4559\n",
      "Epoch [9/500] : Batch [8/10] : Train Loss = 0.0631, Train R2 = 0.4402\n",
      "Epoch [9/500] : Batch [9/10] : Train Loss = 0.0609, Train R2 = 0.4448\n",
      "Epoch [9/500] : Batch [10/10] : Train Loss = 0.0589, Train R2 = 0.4391\n",
      "Epoch [9/500]: Test Loss = 0.4028, Test R2 = 0.0019\n",
      "Epoch [10/500] : Batch [1/10] : Train Loss = 0.1466, Train R2 = 0.5129\n",
      "Epoch [10/500] : Batch [2/10] : Train Loss = 0.0953, Train R2 = 0.4293\n",
      "Epoch [10/500] : Batch [3/10] : Train Loss = 0.0867, Train R2 = 0.4243\n",
      "Epoch [10/500] : Batch [4/10] : Train Loss = 0.0791, Train R2 = 0.3913\n",
      "Epoch [10/500] : Batch [5/10] : Train Loss = 0.0709, Train R2 = 0.3846\n",
      "Epoch [10/500] : Batch [6/10] : Train Loss = 0.0732, Train R2 = 0.3640\n",
      "Epoch [10/500] : Batch [7/10] : Train Loss = 0.0677, Train R2 = 0.3618\n",
      "Epoch [10/500] : Batch [8/10] : Train Loss = 0.0638, Train R2 = 0.3645\n",
      "Epoch [10/500] : Batch [9/10] : Train Loss = 0.0635, Train R2 = 0.3658\n",
      "Epoch [10/500] : Batch [10/10] : Train Loss = 0.0607, Train R2 = 0.3618\n",
      "Epoch [10/500]: Test Loss = 0.3540, Test R2 = 0.0000\n",
      "Epoch [11/500] : Batch [1/10] : Train Loss = 0.0284, Train R2 = 0.4078\n",
      "Epoch [11/500] : Batch [2/10] : Train Loss = 0.0313, Train R2 = 0.3941\n",
      "Epoch [11/500] : Batch [3/10] : Train Loss = 0.0324, Train R2 = 0.3760\n",
      "Epoch [11/500] : Batch [4/10] : Train Loss = 0.0325, Train R2 = 0.3724\n",
      "Epoch [11/500] : Batch [5/10] : Train Loss = 0.0348, Train R2 = 0.3906\n",
      "Epoch [11/500] : Batch [6/10] : Train Loss = 0.0566, Train R2 = 0.3661\n",
      "Epoch [11/500] : Batch [7/10] : Train Loss = 0.0688, Train R2 = 0.3818\n",
      "Epoch [11/500] : Batch [8/10] : Train Loss = 0.0873, Train R2 = 0.4176\n",
      "Epoch [11/500] : Batch [9/10] : Train Loss = 0.0827, Train R2 = 0.4158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/500] : Batch [10/10] : Train Loss = 0.0810, Train R2 = 0.4165\n",
      "Epoch [11/500]: Test Loss = 0.3902, Test R2 = 0.0020\n",
      "Epoch [12/500] : Batch [1/10] : Train Loss = 0.1270, Train R2 = 0.2811\n",
      "Epoch [12/500] : Batch [2/10] : Train Loss = 0.1085, Train R2 = 0.3469\n",
      "Epoch [12/500] : Batch [3/10] : Train Loss = 0.0911, Train R2 = 0.3752\n",
      "Epoch [12/500] : Batch [4/10] : Train Loss = 0.1321, Train R2 = 0.4037\n",
      "Epoch [12/500] : Batch [5/10] : Train Loss = 0.1211, Train R2 = 0.4161\n",
      "Epoch [12/500] : Batch [6/10] : Train Loss = 0.1181, Train R2 = 0.4363\n",
      "Epoch [12/500] : Batch [7/10] : Train Loss = 0.1149, Train R2 = 0.4204\n",
      "Epoch [12/500] : Batch [8/10] : Train Loss = 0.1123, Train R2 = 0.4266\n",
      "Epoch [12/500] : Batch [9/10] : Train Loss = 0.1065, Train R2 = 0.4315\n",
      "Epoch [12/500] : Batch [10/10] : Train Loss = 0.1054, Train R2 = 0.4344\n",
      "Epoch [12/500]: Test Loss = 0.4043, Test R2 = 0.0000\n",
      "Epoch [13/500] : Batch [1/10] : Train Loss = 0.1245, Train R2 = 0.2495\n",
      "Epoch [13/500] : Batch [2/10] : Train Loss = 0.1519, Train R2 = 0.4082\n",
      "Epoch [13/500] : Batch [3/10] : Train Loss = 0.1612, Train R2 = 0.3628\n",
      "Epoch [13/500] : Batch [4/10] : Train Loss = 0.1403, Train R2 = 0.3530\n",
      "Epoch [13/500] : Batch [5/10] : Train Loss = 0.1355, Train R2 = 0.3744\n",
      "Epoch [13/500] : Batch [6/10] : Train Loss = 0.1246, Train R2 = 0.3800\n",
      "Epoch [13/500] : Batch [7/10] : Train Loss = 0.1130, Train R2 = 0.3776\n",
      "Epoch [13/500] : Batch [8/10] : Train Loss = 0.1048, Train R2 = 0.3767\n",
      "Epoch [13/500] : Batch [9/10] : Train Loss = 0.1011, Train R2 = 0.3842\n",
      "Epoch [13/500] : Batch [10/10] : Train Loss = 0.0961, Train R2 = 0.3842\n",
      "Epoch [13/500]: Test Loss = 0.3969, Test R2 = 0.0236\n",
      "Epoch [14/500] : Batch [1/10] : Train Loss = 0.0356, Train R2 = 0.3792\n",
      "Epoch [14/500] : Batch [2/10] : Train Loss = 0.0387, Train R2 = 0.3492\n",
      "Epoch [14/500] : Batch [3/10] : Train Loss = 0.0502, Train R2 = 0.3233\n",
      "Epoch [14/500] : Batch [4/10] : Train Loss = 0.0493, Train R2 = 0.3495\n",
      "Epoch [14/500] : Batch [5/10] : Train Loss = 0.0499, Train R2 = 0.3463\n",
      "Epoch [14/500] : Batch [6/10] : Train Loss = 0.0498, Train R2 = 0.3770\n",
      "Epoch [14/500] : Batch [7/10] : Train Loss = 0.0604, Train R2 = 0.3903\n",
      "Epoch [14/500] : Batch [8/10] : Train Loss = 0.0603, Train R2 = 0.4136\n",
      "Epoch [14/500] : Batch [9/10] : Train Loss = 0.0869, Train R2 = 0.4254\n",
      "Epoch [14/500] : Batch [10/10] : Train Loss = 0.0907, Train R2 = 0.4493\n",
      "Epoch [14/500]: Test Loss = 0.3716, Test R2 = 0.0000\n",
      "Epoch [15/500] : Batch [1/10] : Train Loss = 0.0626, Train R2 = 0.2822\n",
      "Epoch [15/500] : Batch [2/10] : Train Loss = 0.0629, Train R2 = 0.3300\n",
      "Epoch [15/500] : Batch [3/10] : Train Loss = 0.0603, Train R2 = 0.3229\n",
      "Epoch [15/500] : Batch [4/10] : Train Loss = 0.0732, Train R2 = 0.4037\n",
      "Epoch [15/500] : Batch [5/10] : Train Loss = 0.0894, Train R2 = 0.3688\n",
      "Epoch [15/500] : Batch [6/10] : Train Loss = 0.1105, Train R2 = 0.3998\n",
      "Epoch [15/500] : Batch [7/10] : Train Loss = 0.1039, Train R2 = 0.3936\n",
      "Epoch [15/500] : Batch [8/10] : Train Loss = 0.1012, Train R2 = 0.3790\n",
      "Epoch [15/500] : Batch [9/10] : Train Loss = 0.0982, Train R2 = 0.3740\n",
      "Epoch [15/500] : Batch [10/10] : Train Loss = 0.1004, Train R2 = 0.3767\n",
      "Epoch [15/500]: Test Loss = 0.2897, Test R2 = 0.0662\n",
      "Epoch [16/500] : Batch [1/10] : Train Loss = 0.0576, Train R2 = 0.3677\n",
      "Epoch [16/500] : Batch [2/10] : Train Loss = 0.0632, Train R2 = 0.4309\n",
      "Epoch [16/500] : Batch [3/10] : Train Loss = 0.0806, Train R2 = 0.4722\n",
      "Epoch [16/500] : Batch [4/10] : Train Loss = 0.0709, Train R2 = 0.4351\n",
      "Epoch [16/500] : Batch [5/10] : Train Loss = 0.0724, Train R2 = 0.4323\n",
      "Epoch [16/500] : Batch [6/10] : Train Loss = 0.0664, Train R2 = 0.4304\n"
     ]
    }
   ],
   "source": [
    "first_epoch = 0\n",
    "num_epochs = 500\n",
    "save_every = 5\n",
    "\n",
    "training_test_loop(first_epoch,num_epochs,save_every)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be noted that the results visualized in this notebook are relared to the trial dataset of 80 training data and 16 test data, and **they are not representative of the results illustrated in the paper**, for which a training dataset of 8000 data and a test dataset of 2000 data are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
